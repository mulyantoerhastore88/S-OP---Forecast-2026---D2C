import streamlit as st
import pandas as pd
import numpy as np
import gspread
import plotly.graph_objects as go
import plotly.express as px
from google.oauth2.service_account import Credentials
import json
from datetime import datetime
import re
from dateutil.relativedelta import relativedelta
from st_aggrid import AgGrid, GridOptionsBuilder, GridUpdateMode, DataReturnMode, JsCode
from streamlit_extras.metric_cards import style_metric_cards
from streamlit_extras.stylable_container import stylable_container

# ============================================================================
# PAGE CONFIG
# ============================================================================
st.set_page_config(
    page_title="ERHA S&OP Dashboard V5.5",  # SPASI BIASA DI SINI
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================================
# CSS STYLING
# ============================================================================
st.markdown("""
<style>
Â  Â  .main-header {
Â  Â  Â  Â  background: linear-gradient(135deg, #0F172A 0%, #1E293B 100%);
Â  Â  Â  Â  padding: 1.5rem;
Â  Â  Â  Â  border-radius: 12px;
Â  Â  Â  Â  color: white;
Â  Â  Â  Â  margin-bottom: 2rem;
Â  Â  Â  Â  box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1);
Â  Â  }
Â  Â  .stSelectbox label { font-weight: bold; }
Â  Â  div[data-testid="stMetricValue"] { font-size: 1.4rem; }
Â  Â Â 
Â  Â  .block-container {
Â  Â  Â  Â  padding-top: 2rem;
Â  Â  Â  Â  padding-bottom: 2rem;
Â  Â  Â  Â  padding-left: 2rem;
Â  Â  Â  Â  padding-right: 2rem;
Â  Â  Â  Â  max-width: 100%;
Â  Â  }
</style>
""", unsafe_allow_html=True)

# ============================================================================
# 1. GSHEET CONNECTOR
# ============================================================================
class GSheetConnector:
Â  Â  def __init__(self):
Â  Â  Â  Â  if "gsheets" in st.secrets:
Â  Â  Â  Â  Â  Â  self.sheet_id = st.secrets["gsheets"]["sheet_id"]
Â  Â  Â  Â  Â  Â  self.service_account_info = json.loads(st.secrets["gsheets"]["service_account_info"])
Â  Â  Â  Â  Â  Â  self.client = None
Â  Â  Â  Â  Â  Â  self.connect()
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.error("âŒ Secrets 'gsheets' not found.")

Â  Â  def connect(self):
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  scope = ['https://www.googleapis.com/auth/spreadsheets']
Â  Â  Â  Â  Â  Â  creds = Credentials.from_service_account_info(self.service_account_info, scopes=scope)
Â  Â  Â  Â  Â  Â  self.client = gspread.authorize(creds)
Â  Â  Â  Â  Â  Â  self.sheet = self.client.open_by_key(self.sheet_id)
Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  st.error(f"Connection Error: {str(e)}")

Â  Â  def get_sheet_data(self, sheet_name):
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  worksheet = self.sheet.worksheet(sheet_name)
Â  Â  Â  Â  Â  Â  data = worksheet.get_all_records(value_render_option='FORMATTED_VALUE')Â 
Â  Â  Â  Â  Â  Â  return pd.DataFrame(data)
Â  Â  Â  Â  except:
Â  Â  Â  Â  Â  Â  return pd.DataFrame()

Â  Â  def save_data(self, df, sheet_name):
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  Â  Â  worksheet = self.sheet.worksheet(sheet_name)
Â  Â  Â  Â  Â  Â  except gspread.WorksheetNotFound:
Â  Â  Â  Â  Â  Â  Â  Â  worksheet = self.sheet.add_worksheet(title=sheet_name, rows=1000, cols=20)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  df_clean = df.fillna('')
Â  Â  Â  Â  Â  Â  data_to_upload = [df_clean.columns.values.tolist()] + df_clean.values.tolist()
Â  Â  Â  Â  Â  Â  worksheet.clear()
Â  Â  Â  Â  Â  Â  worksheet.update(data_to_upload)
Â  Â  Â  Â  Â  Â  return True, "Success"
Â  Â  Â  Â  except Exception as e:
Â  Â  Â  Â  Â  Â  return False, str(e)

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================
def clean_currency(val):
Â  Â  if pd.isna(val) or val == '': return 0
Â  Â  val_str = str(val)
Â  Â  # Hapus Rp, spasi, koma
Â  Â  clean_str = re.sub(r'[^0-9]', '', val_str)
Â  Â  try:
Â  Â  Â  Â  return float(clean_str)
Â  Â  except:
Â  Â  Â  Â  return 0

def find_matching_column(target_month, available_columns):
Â  Â  if target_month in available_columns: return target_month
Â  Â  target_clean = target_month.lower().replace('-', '').replace(' ', '').replace('_', '')
Â  Â  for col in available_columns:
Â  Â  Â  Â  col_clean = str(col).lower().replace('-', '').replace(' ', '').replace('_', '')
Â  Â  Â  Â  if target_clean in col_clean: return col
Â  Â  return None

# ============================================================================
# 2. DATA LOADER
# ============================================================================
@st.cache_data(ttl=300, show_spinner=False)
def load_data_v5(start_date_str):
Â  Â  try:
Â  Â  Â  Â  gs = GSheetConnector()
Â  Â  Â  Â  sales_df = gs.get_sheet_data("sales_history")
Â  Â  Â  Â  rofo_df = gs.get_sheet_data("rofo_current")
Â  Â  Â  Â  stock_df = gs.get_sheet_data("stock_onhand")
Â  Â  Â  Â Â 
Â  Â  Â  Â  for df in [sales_df, rofo_df, stock_df]:
Â  Â  Â  Â  Â  Â  if not df.empty:
Â  Â  Â  Â  Â  Â  Â  Â  df.columns = [str(c).strip() for c in df.columns]
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  if sales_df.empty or rofo_df.empty: return pd.DataFrame()

Â  Â  Â  Â  # Horizon
Â  Â  Â  Â  start_date = datetime.strptime(start_date_str, "%b-%y")
Â  Â  Â  Â  horizon_months = [(start_date + relativedelta(months=i)).strftime("%b-%y") for i in range(12)]
Â  Â  Â  Â  st.session_state.horizon_months = horizon_months
Â  Â  Â  Â Â 
Â  Â  Â  Â  # FIX FLOOR PRICE
Â  Â  Â  Â  if 'floor_price' in rofo_df.columns:
Â  Â  Â  Â  Â  Â  rofo_df['floor_price'] = rofo_df['floor_price'].apply(clean_currency)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  floor_cols = [c for c in rofo_df.columns if 'floor' in c.lower()]
Â  Â  Â  Â  Â  Â  if floor_cols:
Â  Â  Â  Â  Â  Â  Â  Â  rofo_df.rename(columns={floor_cols[0]: 'floor_price'}, inplace=True)
Â  Â  Â  Â  Â  Â  Â  Â  rofo_df['floor_price'] = rofo_df['floor_price'].apply(clean_currency)
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  rofo_df['floor_price'] = 0

Â  Â  Â  Â  # Rename Keys
Â  Â  Â  Â  key_map = {'Product Name': 'Product_Name', 'Brand Group': 'Brand_Group', 'SKU Tier': 'SKU_Tier'}
Â  Â  Â  Â  sales_df.rename(columns=key_map, inplace=True)
Â  Â  Â  Â  rofo_df.rename(columns=key_map, inplace=True)
Â  Â  Â  Â Â 
Â  Â  Â  Â  possible_keys = ['sku_code', 'Product_Name', 'Brand', 'Brand_Group', 'SKU_Tier', 'Channel']
Â  Â  Â  Â  valid_keys = [k for k in possible_keys if k in sales_df.columns and k in rofo_df.columns]
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Sales L3M
Â  Â  Â  Â  sales_date_cols = [c for c in sales_df.columns if '-' in c]
Â  Â  Â  Â  l3m_cols = sales_date_cols[-3:] if len(sales_date_cols) >= 3 else sales_date_cols
Â  Â  Â  Â  if l3m_cols:
Â  Â  Â  Â  Â  Â  sales_df['L3M_Avg'] = sales_df[l3m_cols].replace('', 0).astype(str).applymap(clean_currency).mean(axis=1).round(0)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  sales_df['L3M_Avg'] = 0
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  sales_subset = sales_df[valid_keys + ['L3M_Avg'] + l3m_cols].copy()
Â  Â  Â  Â Â 
Â  Â  Â  Â  # ROFO Cols
Â  Â  Â  Â  rofo_cols_to_fetch = valid_keys.copy()
Â  Â  Â  Â  for extra in ['Channel', 'Product_Focus', 'floor_price']:
Â  Â  Â  Â  Â  Â  if extra in rofo_df.columns and extra not in rofo_cols_to_fetch:
Â  Â  Â  Â  Â  Â  Â  Â  rofo_cols_to_fetch.append(extra)
Â  Â  Â  Â Â 
Â  Â  Â  Â  month_mapping = {}
Â  Â  Â  Â  missing_months = []
Â  Â  Â  Â  for m in horizon_months:
Â  Â  Â  Â  Â  Â  real_col = find_matching_column(m, rofo_df.columns)
Â  Â  Â  Â  Â  Â  if real_col:
Â  Â  Â  Â  Â  Â  Â  Â  month_mapping[m] = real_col
Â  Â  Â  Â  Â  Â  Â  Â  if real_col not in rofo_cols_to_fetch: rofo_cols_to_fetch.append(real_col)
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  missing_months.append(m)
Â  Â  Â  Â  st.session_state.missing_months = missing_months
Â  Â  Â  Â Â 
Â  Â  Â  Â  rofo_subset = rofo_df[rofo_cols_to_fetch].copy()
Â  Â  Â  Â  inv_map = {v: k for k, v in month_mapping.items()}
Â  Â  Â  Â  rofo_subset.rename(columns=inv_map, inplace=True)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Merge
Â  Â  Â  Â  merged_df = pd.merge(sales_subset, rofo_subset, on=valid_keys, how='inner')
Â  Â  Â  Â Â 
Â  Â  Â  Â  if 'Product_Focus' not in merged_df.columns: merged_df['Product_Focus'] = ""
Â  Â  Â  Â  else: merged_df['Product_Focus'] = merged_df['Product_Focus'].fillna("")
Â  Â  Â  Â Â 
Â  Â  Â  Â  if 'floor_price' not in merged_df.columns: merged_df['floor_price'] = 0
Â  Â  Â  Â  else: merged_df['floor_price'] = merged_df['floor_price'].fillna(0)
Â  Â  Â  Â Â 
Â  Â  Â  Â  for m in horizon_months:
Â  Â  Â  Â  Â  Â  if m not in merged_df.columns: merged_df[m] = 0
Â  Â  Â  Â  Â  Â  else: merged_df[m] = merged_df[m].apply(clean_currency)

Â  Â  Â  Â  # Stock
Â  Â  Â  Â  if not stock_df.empty and 'sku_code' in stock_df.columns:
Â  Â  Â  Â  Â  Â  stock_col = 'Stock_Qty' if 'Stock_Qty' in stock_df.columns else stock_df.columns[1]
Â  Â  Â  Â  Â  Â  merged_df = pd.merge(merged_df, stock_df[['sku_code', stock_col]], on='sku_code', how='left')
Â  Â  Â  Â  Â  Â  merged_df.rename(columns={stock_col: 'Stock_Qty'}, inplace=True)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  merged_df['Stock_Qty'] = 0
Â  Â  Â  Â  merged_df['Stock_Qty'] = merged_df['Stock_Qty'].apply(clean_currency)

Â  Â  Â  Â  # Metrics
Â  Â  Â  Â  merged_df['Month_Cover'] = (merged_df['Stock_Qty'] / merged_df['L3M_Avg'].replace(0, 1)).round(1)
Â  Â  Â  Â  merged_df['Month_Cover'] = merged_df['Month_Cover'].replace([np.inf, -np.inf], 0)
Â  Â  Â  Â Â 
Â  Â  Â  Â  cycle_months = horizon_months[:3]
Â  Â  Â  Â  for m in cycle_months:
Â  Â  Â  Â  Â  Â  merged_df[f'Cons_{m}'] = merged_df[m]
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  return merged_df

Â  Â  except Exception as e:
Â  Â  Â  Â  st.error(f"Error Loading: {str(e)}")
Â  Â  Â  Â  return pd.DataFrame()

def calculate_pct(df, months):
Â  Â  df_calc = df.copy()
Â  Â  for m in months:
Â  Â  Â  Â  if f'Cons_{m}' in df_calc.columns:
Â  Â  Â  Â  Â  Â  pct = (df_calc[f'Cons_{m}'] / df_calc['L3M_Avg'].replace(0, np.nan) * 100).round(1)
Â  Â  Â  Â  Â  Â  df_calc[f'{m}_%'] = pct.replace([np.inf, -np.inf], 0).fillna(100)
Â  Â  return df_calc

# ============================================================================
# SIDEBAR
# ============================================================================
with st.sidebar:
Â  Â  st.image("https://www.erhagroup.com/assets/img/logo-erha.png", width=150)
Â  Â  st.markdown("### âš™ï¸ Planning Cycle")
Â  Â  curr_date = datetime.now()
Â  Â  start_list = [curr_date + relativedelta(months=i) for i in range(-1, 3)]
Â  Â  option_map = {d.strftime("%b-%y"): d for d in start_list}
Â  Â  default_idx = 1 if curr_date.day < 5 else 2
Â  Â  selected_start_str = st.selectbox("Forecast Start Month", options=list(option_map.keys()), index=default_idx)
Â  Â  start_date = option_map[selected_start_str]
Â  Â  cycle_months = [
Â  Â  Â  Â  (start_date).strftime("%b-%y"),
Â  Â  Â  Â  (start_date + relativedelta(months=1)).strftime("%b-%y"),
Â  Â  Â  Â  (start_date + relativedelta(months=2)).strftime("%b-%y")
Â  Â  ]
Â  Â  st.session_state.adjustment_months = cycle_months
Â  Â  st.info(f"**Cycle:** {', '.join(cycle_months)}")
Â  Â  if st.button("ğŸ”„ Reload Data"): st.cache_data.clear(); st.rerun()
Â  Â  with st.expander("ğŸ•µï¸ Debugger"):
Â  Â  Â  Â  if 'missing_months' in st.session_state and st.session_state.missing_months:
Â  Â  Â  Â  Â  Â  st.error(f"Missing: {st.session_state.missing_months}")
Â  Â  Â  Â  else: st.success("All 12-Month Columns Found/Mapped!")

# ============================================================================
# MAIN
# ============================================================================
st.markdown(f"""
<div class="main-header">
Â  Â  <h2>ğŸ“Š ERHA S&OP Dashboard V5.5</h2>
Â  Â  <p>Horizon: <b>{cycle_months[0]} - {cycle_months[2]} (Consensus)</b> + Next 9 Months (ROFO)</p>
</div>
""", unsafe_allow_html=True)

all_df = load_data_v5(selected_start_str)
if all_df.empty: st.warning("No data found."); st.stop()

# FILTER
with stylable_container(key="filters", css_styles="{background:white; padding:15px; border-radius:10px; border:1px solid #E2E8F0;}"):
Â  Â  c1, c2, c3, c4, c5 = st.columns(5)
Â  Â  with c1:
Â  Â  Â  Â  channels = ["ALL"] + sorted(all_df['Channel'].dropna().unique().tolist()) if 'Channel' in all_df.columns else ["ALL"]
Â  Â  Â  Â  sel_channel = st.selectbox("ğŸ›’ Channel", channels)
Â  Â  with c2:
Â  Â  Â  Â  brands = ["ALL"] + sorted(all_df['Brand'].dropna().unique().tolist()) if 'Brand' in all_df.columns else ["ALL"]
Â  Â  Â  Â  sel_brand = st.selectbox("ğŸ·ï¸ Brand", brands)
Â  Â  with c3:
Â  Â  Â  Â  b_groups = ["ALL"] + sorted(all_df['Brand_Group'].dropna().unique().tolist()) if 'Brand_Group' in all_df.columns else ["ALL"]
Â  Â  Â  Â  sel_group = st.selectbox("ğŸ“¦ Brand Group", b_groups)
Â  Â  with c4:
Â  Â  Â  Â  tiers = ["ALL"] + sorted(all_df['SKU_Tier'].dropna().unique().tolist()) if 'SKU_Tier' in all_df.columns else ["ALL"]
Â  Â  Â  Â  sel_tier = st.selectbox("ğŸ’ Tier", tiers)
Â  Â  with c5:
Â  Â  Â  Â  covers = ["ALL", "Over (>1.5)", "Healthy", "Low"]
Â  Â  Â  Â  sel_cover = st.selectbox("ğŸ“‰ Stock Cover", covers)

filtered_df = all_df.copy()
if sel_channel != "ALL" and 'Channel' in filtered_df.columns: filtered_df = filtered_df[filtered_df['Channel'] == sel_channel]
if sel_brand != "ALL": filtered_df = filtered_df[filtered_df['Brand'] == sel_brand]
if sel_group != "ALL": filtered_df = filtered_df[filtered_df['Brand_Group'] == sel_group]
if sel_tier != "ALL": filtered_df = filtered_df[filtered_df['SKU_Tier'] == sel_tier]
if sel_cover == "Over (>1.5)": filtered_df = filtered_df[filtered_df['Month_Cover'] > 1.5]

tab1, tab2 = st.tabs(["ğŸ“ Forecast Worksheet", "ğŸ“ˆ Analytics"])

# ============================================================================
# TAB 1: WORKSHEET
# ============================================================================
with tab1:
Â  Â  edit_df = filtered_df.copy()
Â  Â  edit_df = calculate_pct(edit_df, cycle_months)
Â  Â Â 
Â  Â  ag_cols = ['sku_code', 'Product_Name', 'Channel', 'Brand', 'SKU_Tier', 'Product_Focus', 'floor_price']
Â  Â Â 
Â  Â  hist_cols = [c for c in edit_df.columns if '-' in c and c not in st.session_state.horizon_months and 'Cons' not in c and '%' not in c][-3:]
Â  Â  ag_cols.extend(hist_cols)
Â  Â  ag_cols.extend(['L3M_Avg', 'Stock_Qty', 'Month_Cover'])
Â  Â Â 
Â  Â  ag_cols.extend(st.session_state.horizon_months)Â 
Â  Â Â 
Â  Â  ag_cols.extend([f'{m}_%' for m in cycle_months])
Â  Â  ag_cols.extend([f'Cons_{m}' for m in cycle_months])
Â  Â Â 
Â  Â  ag_cols = list(dict.fromkeys(ag_cols))
Â  Â  ag_cols = [c for c in ag_cols if c in edit_df.columns]
Â  Â Â 
Â  Â  ag_df = edit_df[ag_cols].copy()

Â  Â  # JS Code
Â  Â  js_sku_focus = JsCode("function(p) { if(p.data.Product_Focus === 'Yes') return {'backgroundColor': '#CCFBF1', 'color': '#0F766E', 'fontWeight': 'bold', 'borderLeft': '4px solid #14B8A6'}; return null; }")
Â  Â  js_brand = JsCode("function(p) { if(!p.value) return null; const b=p.value.toLowerCase(); if(b.includes('acne')) return {'backgroundColor':'#E0F2FE','color':'#0284C7','fontWeight':'bold'}; if(b.includes('tru')) return {'backgroundColor':'#DCFCE7','color':'#16A34A','fontWeight':'bold'}; if(b.includes('hair')) return {'backgroundColor':'#FEF3C7','color':'#D97706','fontWeight':'bold'}; if(b.includes('age')) return {'backgroundColor':'#E0E7FF','color':'#4F46E5','fontWeight':'bold'}; if(b.includes('his')) return {'backgroundColor':'#F3E8FF','color':'#7C3AED','fontWeight':'bold'}; return {'backgroundColor':'#F3F4F6'}; }")
Â  Â  js_channel = JsCode("function(p) { if(!p.value) return null; if(p.value==='E-commerce') return {'color':'#EA580C','fontWeight':'bold'}; if(p.value==='Reseller') return {'color':'#059669','fontWeight':'bold'}; return null; }")
Â  Â  js_cover = JsCode("function(p) { if(p.value > 1.5) return {'backgroundColor': '#FCE7F3', 'color': '#BE185D', 'fontWeight': 'bold'}; return null; }")
Â  Â  js_pct = JsCode("function(p) { if(p.value < 90) return {'backgroundColor': '#FFEDD5', 'color': '#9A3412', 'fontWeight': 'bold'}; if(p.value > 130) return {'backgroundColor': '#FEE2E2', 'color': '#991B1B', 'fontWeight': 'bold'}; return {'color': '#374151'}; }")
Â  Â  js_edit = JsCode("function(p) { return {'backgroundColor': '#EFF6FF', 'border': '1px solid #93C5FD', 'fontWeight': 'bold', 'color': '#1E40AF'}; }")

Â  Â  # Grid Config
Â  Â  gb = GridOptionsBuilder.from_dataframe(ag_df)
Â  Â  gb.configure_grid_options(rowHeight=35, headerHeight=40)
Â  Â  gb.configure_default_column(resizable=True, filterable=True, sortable=True, editable=False, minWidth=95)
Â  Â Â 
Â  Â  gb.configure_column("sku_code", pinned="left", width=100, cellStyle=js_sku_focus)
Â  Â  gb.configure_column("Product_Name", pinned="left", minWidth=200, flex=1)
Â  Â  gb.configure_column("Channel", pinned="left", width=110, cellStyle=js_channel)
Â  Â  gb.configure_column("Product_Focus", hide=True)
Â  Â  gb.configure_column("floor_price", hide=True)Â 
Â  Â  gb.configure_column("Brand", cellStyle=js_brand, width=120)
Â  Â  gb.configure_column("Month_Cover", cellStyle=js_cover, width=100)
Â  Â Â 
Â  Â  for m in st.session_state.horizon_months:
Â  Â  Â  Â  if m not in cycle_months: gb.configure_column(m, hide=True)
Â  Â Â 
Â  Â  for c in ag_cols:
Â  Â  Â  Â  if c not in ['sku_code', 'Product_Name', 'Channel', 'Brand', 'SKU_Tier', 'Month_Cover', 'Product_Focus', 'floor_price'] and '%' not in c:
Â  Â  Â  Â  Â  Â  gb.configure_column(c, type=["numericColumn"], valueFormatter="x.toLocaleString()", minWidth=105)
Â  Â  Â  Â  Â  Â Â 
Â  Â  for m in cycle_months:
Â  Â  Â  Â  if f'{m}_%' in ag_cols: gb.configure_column(f'{m}_%', header_name=f"{m} %", type=["numericColumn"], valueFormatter="x.toFixed(1) + '%'", cellStyle=js_pct, minWidth=90)
Â  Â  Â  Â  if f'Cons_{m}' in ag_cols: gb.configure_column(f'Cons_{m}', header_name=f"âœï¸ {m}", editable=True, cellStyle=js_edit, width=115, pinned="right", type=["numericColumn"], valueFormatter="x.toLocaleString()")

Â  Â  gb.configure_selection('single')
Â  Â Â 
Â  Â  grid_res = AgGrid(ag_df, gridOptions=gb.build(), allow_unsafe_jscode=True, update_mode=GridUpdateMode.VALUE_CHANGED, height=600, theme='alpine', key='v5_worksheet', use_container_width=True)
Â  Â  updated_df = pd.DataFrame(grid_res['data'])

Â  Â  # Save Logic
Â  Â  st.markdown("---")
Â  Â  c_save, c_push, c_info = st.columns([1, 1, 2])
Â  Â  with c_save:
Â  Â  Â  Â  if st.button("ğŸ’¾ Save (Local)", type="primary", use_container_width=True):
Â  Â  Â  Â  Â  Â  st.session_state.edited_v5 = updated_df.copy()
Â  Â  Â  Â  Â  Â  st.success("Saved!")
Â  Â  with c_push:
Â  Â  Â  Â  if st.button("â˜ï¸ Push (GSheets)", type="secondary", use_container_width=True):
Â  Â  Â  Â  Â  Â  if 'edited_v5' not in st.session_state: st.warning("Save locally first!")
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  with st.spinner("Pushing..."):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  keep = ['sku_code', 'Product_Name', 'Channel', 'Brand', 'SKU_Tier', 'Product_Focus'] + [f'Cons_{m}' for m in cycle_months]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  final = st.session_state.edited_v5[keep].copy()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  final['Last_Update'] = datetime.now().strftime('%Y-%m-%d %H:%M')
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  gs = GSheetConnector()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ok, msg = gs.save_data(final, "consensus_rofo")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if ok: st.balloons(); st.success("Done!")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  else: st.error(msg)
Â  Â  with c_info:
Â  Â  Â  Â  total = 0
Â  Â  Â  Â  for m in cycle_months:
Â  Â  Â  Â  Â  Â  Â if f'Cons_{m}' in updated_df.columns: total += updated_df[f'Cons_{m}'].sum()
Â  Â  Â  Â  st.metric("Total Consensus (M1-M3)", f"{total:,.0f}")

# ============================================================================
# TAB 2: ANALYTICS (UPGRADED)
# ============================================================================
with tab2:
Â  Â  st.markdown("### ğŸ“ˆ Projection Analytics")
Â  Â Â 
Â  Â  base_df = updated_df if not updated_df.empty else filtered_df
Â  Â  if base_df.empty: st.stop()
Â  Â  Â  Â Â 
Â  Â  full_horizon = st.session_state.horizon_months
Â  Â Â 
Â  Â  # --- CONTROLS ---
Â  Â  c_view, c_year = st.columns([2, 1])
Â  Â  with c_view:
Â  Â  Â  Â  chart_view = st.radio("Chart View:", ["Total Volume", "Breakdown by Brand"], horizontal=True)
Â  Â  with c_year:
Â  Â  Â  Â  show_2026_only = st.checkbox("ğŸ“… View 2026 Only", value=False)

Â  Â  # --- FILTER ACTIVE MONTHS ---
Â  Â  if show_2026_only:
Â  Â  Â  Â  active_months = [m for m in full_horizon if "-26" in m]
Â  Â  else:
Â  Â  Â  Â  active_months = full_horizon

Â  Â  # Calculate Values based on Active Months
Â  Â  calc_df = base_df.copy()
Â  Â  if 'floor_price' not in calc_df.columns: calc_df['floor_price'] = 0
Â  Â Â 
Â  Â  total_qty_cols = []
Â  Â  total_val_cols = []
Â  Â Â 
Â  Â  for m in active_months:
Â  Â  Â  Â  qty_col = f'Final_Qty_{m}'
Â  Â  Â  Â  val_col = f'Final_Val_{m}'
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Source
Â  Â  Â  Â  if m in cycle_months: source_col = f'Cons_{m}'
Â  Â  Â  Â  else: source_col = m
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  if source_col in calc_df.columns:
Â  Â  Â  Â  Â  Â  calc_df[qty_col] = pd.to_numeric(calc_df[source_col], errors='coerce').fillna(0)
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  calc_df[qty_col] = 0
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  calc_df[val_col] = calc_df[qty_col] * calc_df['floor_price']
Â  Â  Â  Â Â 
Â  Â  Â  Â  total_qty_cols.append(qty_col)
Â  Â  Â  Â  total_val_cols.append(val_col)

Â  Â  # TOP METRICS (ACTIVE VIEW)
Â  Â  grand_total_qty = calc_df[total_qty_cols].sum().sum()
Â  Â  grand_total_val = calc_df[total_val_cols].sum().sum()
Â  Â Â 
Â  Â  with stylable_container(key="kpi_v5", css_styles="{background-color:#F1F5F9; padding:20px; border-radius:10px; border:1px solid #CBD5E1;}"):
Â  Â  Â  Â  k1, k2 = st.columns(2)
Â  Â  Â  Â  period_label = "2026 Only" if show_2026_only else "12-Month"
Â  Â  Â  Â  with k1: st.metric(f"{period_label} Volume", f"{grand_total_qty:,.0f} pcs", "Forecast")
Â  Â  Â  Â  with k2: st.metric(f"{period_label} Revenue", f"Rp {grand_total_val/1_000_000_000:,.2f} M", "Estimated @ Floor Price")
Â  Â  Â  Â  Â  Â Â 
Â  Â  st.markdown("---")

Â  Â  # --- PREPARE CHART DATA ---
Â  Â  chart_data = []
Â  Â  if chart_view == "Total Volume":
Â  Â  Â  Â  # Simple Aggregation
Â  Â  Â  Â  for m in active_months:
Â  Â  Â  Â  Â  Â  q = calc_df[f'Final_Qty_{m}'].sum()
Â  Â  Â  Â  Â  Â  v = calc_df[f'Final_Val_{m}'].sum()
Â  Â  Â  Â  Â  Â  chart_data.append({"Month": m, "Volume": q, "Value": v, "Type": "Total"})
Â  Â  else:
Â  Â  Â  Â  # Breakdown by Brand
Â  Â  Â  Â  for m in active_months:
Â  Â  Â  Â  Â  Â  # Group by Brand
Â  Â  Â  Â  Â  Â  grp = calc_df.groupby('Brand')[[f'Final_Qty_{m}', f'Final_Val_{m}']].sum().reset_index()
Â  Â  Â  Â  Â  Â  total_v_month = grp[f'Final_Val_{m}'].sum()
Â  Â  Â  Â  Â  Â  for idx, row in grp.iterrows():
Â  Â  Â  Â  Â  Â  Â  Â  chart_data.append({
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Month": m,Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Brand": row['Brand'],Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Volume": row[f'Final_Qty_{m}'],Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Value": total_v_month # Value line is always Total
Â  Â  Â  Â  Â  Â  Â  Â  })

Â  Â  chart_df = pd.DataFrame(chart_data)
Â  Â Â 
Â  Â  fig_combo = go.Figure()
Â  Â Â 
Â  Â  # 1. BAR CHART (Volume)
Â  Â  if chart_view == "Total Volume":
Â  Â  Â  Â  fig_combo.add_trace(go.Bar(
Â  Â  Â  Â  Â  Â  x=chart_df['Month'], y=chart_df['Volume'],Â 
Â  Â  Â  Â  Â  Â  name='Volume (Qty)', marker_color='#3B82F6', opacity=0.8
Â  Â  Â  Â  ))
Â  Â  else:
Â  Â  Â  Â  # Stacked Bar by Brand
Â  Â  Â  Â  brands = chart_df['Brand'].unique()
Â  Â  Â  Â  # Use a nice color cycle
Â  Â  Â  Â  colors = px.colors.qualitative.Pastel
Â  Â  Â  Â  for i, brand in enumerate(brands):
Â  Â  Â  Â  Â  Â  b_data = chart_df[chart_df['Brand'] == brand]
Â  Â  Â  Â  Â  Â  color = colors[i % len(colors)]
Â  Â  Â  Â  Â  Â  fig_combo.add_trace(go.Bar(
Â  Â  Â  Â  Â  Â  Â  Â  x=b_data['Month'], y=b_data['Volume'],Â 
Â  Â  Â  Â  Â  Â  Â  Â  name=brand, marker_color=color
Â  Â  Â  Â  Â  Â  ))
Â  Â  Â  Â  fig_combo.update_layout(barmode='stack')

Â  Â  # 2. LINE CHART (Total Value) - Always Total
Â  Â  # Need single row per month for the line
Â  Â  line_data = chart_df.drop_duplicates(subset=['Month'])
Â  Â  fig_combo.add_trace(go.Scatter(
Â  Â  Â  Â  x=line_data['Month'], y=line_data['Value'],Â 
Â  Â  Â  Â  name='Total Value (Rp)', yaxis='y2',Â 
Â  Â  Â  Â  line=dict(color='#EF4444', width=3), mode='lines+markers'
Â  Â  ))
Â  Â Â 
Â  Â  fig_combo.update_layout(
Â  Â  Â  Â  title=f"Forecast Trend ({period_label})",
Â  Â  Â  Â  yaxis=dict(title="Volume (Units)", showgrid=False),
Â  Â  Â  Â  yaxis2=dict(title="Value (Rp)", overlaying='y', side='right', showgrid=False),
Â  Â  Â  Â  legend=dict(x=0, y=1.1, orientation='h'),
Â  Â  Â  Â  hovermode="x unified",
Â  Â  Â  Â  height=500
Â  Â  )
Â  Â  st.plotly_chart(fig_combo, use_container_width=True)
Â  Â Â 
Â  Â  # --- BREAKDOWN TABLE ---
Â  Â  with st.expander(f"ğŸ” View Breakdown by Brand ({period_label})", expanded=True):
Â  Â  Â  Â  brand_summ = calc_df.groupby('Brand')[total_val_cols].sum().reset_index()
Â  Â  Â  Â  rename_map = {old: old.replace('Final_Val_', '') for old in total_val_cols}
Â  Â  Â  Â  brand_summ.rename(columns=rename_map, inplace=True)
Â  Â  Â  Â  brand_summ['Total Period'] = brand_summ.iloc[:, 1:].sum(axis=1)
Â  Â  Â  Â  brand_summ = brand_summ.sort_values('Total Period', ascending=False)
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Formatting with Rp and Commas
Â  Â  Â  Â  fmt_df = brand_summ.copy()
Â  Â  Â  Â  for c in fmt_df.columns:
Â  Â  Â  Â  Â  Â  if c != 'Brand':
Â  Â  Â  Â  Â  Â  Â  Â  fmt_df[c] = fmt_df[c].apply(lambda x: f"Rp {x:,.0f}")
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  st.dataframe(fmt_df, hide_index=True, use_container_width=True)

